{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079298f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Marc/Documents/GitHub/immo-eliza-lions/.venv/bin/python\n",
      "2.3.0\n",
      "âœ… Data loaded. Rows: 74381, Columns: 16\n",
      "Data Overview:\n",
      "Rows: 74381\n",
      "Columns: 16\n",
      "\n",
      "Data types:\n",
      "type                          int64\n",
      "subtype                      object\n",
      "bedroomCount                float64\n",
      "bathroomCount               float64\n",
      "province                     object\n",
      "locality                     object\n",
      "habitableSurface            float64\n",
      "buildingCondition           float64\n",
      "buildingConstructionYear    float64\n",
      "heatingType                  object\n",
      "parkingCountIndoor          float64\n",
      "parkingCountOutdoor         float64\n",
      "epcScore                    float64\n",
      "price                       float64\n",
      "region                       object\n",
      "price_per_m2                float64\n",
      "dtype: object\n",
      "\n",
      "Missing Values:\n",
      "type                            0\n",
      "subtype                         0\n",
      "bedroomCount                 2739\n",
      "bathroomCount                9485\n",
      "province                        0\n",
      "locality                        0\n",
      "habitableSurface             8385\n",
      "buildingCondition           17818\n",
      "buildingConstructionYear    26681\n",
      "heatingType                 28119\n",
      "parkingCountIndoor          47146\n",
      "parkingCountOutdoor         56679\n",
      "epcScore                    11269\n",
      "price                           0\n",
      "region                          0\n",
      "price_per_m2                 8385\n",
      "dtype: int64\n",
      "\n",
      "Duplicates: 0\n",
      "\n",
      "Basic Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74381 entries, 0 to 74380\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   type                      74381 non-null  int64  \n",
      " 1   subtype                   74381 non-null  object \n",
      " 2   bedroomCount              71642 non-null  float64\n",
      " 3   bathroomCount             64896 non-null  float64\n",
      " 4   province                  74381 non-null  object \n",
      " 5   locality                  74381 non-null  object \n",
      " 6   habitableSurface          65996 non-null  float64\n",
      " 7   buildingCondition         56563 non-null  float64\n",
      " 8   buildingConstructionYear  47700 non-null  float64\n",
      " 9   heatingType               46262 non-null  object \n",
      " 10  parkingCountIndoor        27235 non-null  float64\n",
      " 11  parkingCountOutdoor       17702 non-null  float64\n",
      " 12  epcScore                  63112 non-null  float64\n",
      " 13  price                     74381 non-null  float64\n",
      " 14  region                    74381 non-null  object \n",
      " 15  price_per_m2              65996 non-null  float64\n",
      "dtypes: float64(10), int64(1), object(5)\n",
      "memory usage: 9.1+ MB\n",
      "None\n",
      "\n",
      "First few rows of the dataset:\n",
      "   type      subtype  bedroomCount  bathroomCount  province   locality  \\\n",
      "0     1    APARTMENT           2.0            1.0  Brussels  Etterbeek   \n",
      "1     0        HOUSE           4.0            2.0  Brussels  Etterbeek   \n",
      "2     1    APARTMENT           2.0            1.0  Brussels  Etterbeek   \n",
      "3     1    APARTMENT           2.0            2.0  Brussels  Bruxelles   \n",
      "4     1  FLAT_STUDIO           1.0            1.0  Brussels  Etterbeek   \n",
      "\n",
      "   habitableSurface  buildingCondition  buildingConstructionYear heatingType  \\\n",
      "0             100.0                4.0                    2004.0         GAS   \n",
      "1             270.0                3.0                    1910.0     FUELOIL   \n",
      "2              87.0                5.0                    1970.0     FUELOIL   \n",
      "3             104.0                5.0                    2018.0         GAS   \n",
      "4              71.0                5.0                    1906.0         GAS   \n",
      "\n",
      "   parkingCountIndoor  parkingCountOutdoor  epcScore     price    region  \\\n",
      "0                 1.0                  NaN       5.0  399000.0  Brussels   \n",
      "1                 NaN                  NaN       3.0  895000.0  Brussels   \n",
      "2                 NaN                  NaN       2.0  465000.0  Brussels   \n",
      "3                 NaN                  NaN       6.0  590000.0  Brussels   \n",
      "4                 NaN                  NaN       3.0  289000.0  Brussels   \n",
      "\n",
      "   price_per_m2  \n",
      "0   3990.000000  \n",
      "1   3314.814815  \n",
      "2   5344.827586  \n",
      "3   5673.076923  \n",
      "4   4070.422535  \n",
      "Number of 'Unknown' values in the 'Region' column: 0\n",
      "âœ… Training set: (59504, 15), Test set: (14877, 15)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'APARTMENT'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/var/folders/yp/grpj3l556fl4nly4zbgbvzb80000gn/T/ipykernel_52065/3327179264.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     61\u001b[39m \n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# === STEP 4: RANDOM FOREST MODEL ===\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Random Forest is a robust regression model that works well with both numerical and categorical (encoded) data.\u001b[39;00m\n\u001b[32m     64\u001b[39m model = RandomForestRegressor(n_estimators=\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m model.fit(X_train, y_train)\n\u001b[32m     66\u001b[39m print(\u001b[33m\"ðŸŒ² Random Forest model trained.\"\u001b[39m)\n\u001b[32m     67\u001b[39m \n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# === STEP 5: FEATURE IMPORTANCE ===\u001b[39;00m\n",
      "\u001b[32m~/Documents/GitHub/immo-eliza-lions/.venv/lib/python3.11/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1359\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m                 )\n\u001b[32m   1362\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~/Documents/GitHub/immo-eliza-lions/.venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;66;03m# Validate or convert input data\u001b[39;00m\n\u001b[32m    356\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"sparse multilabel-indicator for y is not supported.\"\u001b[39m)\n\u001b[32m    358\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         X, y = validate_data(\n\u001b[32m    360\u001b[39m             self,\n\u001b[32m    361\u001b[39m             X,\n\u001b[32m    362\u001b[39m             y,\n",
      "\u001b[32m~/Documents/GitHub/immo-eliza-lions/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2967\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2968\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2969\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2972\u001b[39m         out = X, y\n\u001b[32m   2973\u001b[39m \n\u001b[32m   2974\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32m~/Documents/GitHub/immo-eliza-lions/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m         )\n\u001b[32m   1365\u001b[39m \n\u001b[32m   1366\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1367\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     X = check_array(\n\u001b[32m   1369\u001b[39m         X,\n\u001b[32m   1370\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1371\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32m~/Documents/GitHub/immo-eliza-lions/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) from complex_warning\n",
      "\u001b[32m~/Documents/GitHub/immo-eliza-lions/.venv/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~/Documents/GitHub/immo-eliza-lions/.venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2164\u001b[39m             )\n\u001b[32m   2165\u001b[39m         values = self._values\n\u001b[32m   2166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2167\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2168\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2171\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'APARTMENT'"
     ]
    }
   ],
   "source": [
    "# === STEP 1: IMPORT LIBRARIES ===\n",
    "# These are essential libraries for data manipulation, plotting and modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "#First look after first cleaning\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "\n",
    "# === STEP 2: LOAD CLEANED DATA ===\n",
    "# This dataset was cleaned and saved by clean.py. No further cleaning needed here.\n",
    "file_path = 'data/cleaned/immoweb-dataset_cleaned_mvg.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data = pd.read_csv(\"data/cleaned/immoweb-dataset_cleaned_mvg.csv\")\n",
    "print(f\"âœ… Data loaded. Rows: {len(data)}, Columns: {data.shape[1]}\")\n",
    "\n",
    "# Data Overview\n",
    "print(\"Data Overview:\")\n",
    "print(f\"Rows: {data.shape[0]}\")\n",
    "print(f\"Columns: {data.shape[1]}\")\n",
    "print(\"\\nData types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"\\nDuplicates: {duplicates}\")\n",
    "\n",
    "# Display basic info about the dataset\n",
    "print(\"\\nBasic Information:\")\n",
    "print(data.info())\n",
    "\n",
    "# Show the first few rows of the dataset to inspect the data\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Count the number of \"Unknown\" values in the 'Region' column\n",
    "unknown_count = data[data['region'] == 'Unknown'].shape[0]\n",
    "print(f\"Number of 'Unknown' values in the 'Region' column: {unknown_count}\")\n",
    "\n",
    "\n",
    "# === STEP 3: TRAIN-TEST SPLIT ===\n",
    "# We split the data into training and test sets so that the model can learn on one part\n",
    "# and be evaluated on unseen data.\n",
    "X = data.drop(columns=\"price\")\n",
    "y = data[\"price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"âœ… Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# === STEP 4: RANDOM FOREST MODEL ===\n",
    "# Random Forest is a robust regression model that works well with both numerical and categorical (encoded) data.\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"ðŸŒ² Random Forest model trained.\")\n",
    "\n",
    "# === STEP 5: FEATURE IMPORTANCE ===\n",
    "# This plot helps us understand which features are most important to the modelâ€™s predictions.\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "importances.head(10).plot(kind=\"barh\", color='teal')\n",
    "plt.title(\"Top 10 Feature Importances\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === STEP 6: MODEL PERFORMANCE ===\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"ðŸ“Š Model Performance:\")\n",
    "print(f\"MAE : {mae:,.0f} â‚¬\")\n",
    "print(f\"RMSE: {rmse:,.0f} â‚¬\")\n",
    "print(f\"RÂ²  : {r2:.3f}\")\n",
    "\n",
    "# === STEP 7: PREDICTED VS ACTUAL ===\n",
    "# This scatter plot lets us check how close our predictions are to actual values.\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
    "plt.title(\"Predicted vs Actual Prices\")\n",
    "plt.xlabel(\"Actual Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === STEP 8: MISSING VALUES PLOT ===\n",
    "# Although cleaned, this plot is good for exploratory completeness.\n",
    "missing = data.isnull().mean() * 100\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=missing.index, y=missing.values, palette=\"Blues_r\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "plt.ylabel('Missing Values (%)')\n",
    "plt.title('Missing Values per Column')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === STEP 9: PROPERTY TYPE DISTRIBUTION ===\n",
    "if 'type' in data.columns:\n",
    "    counts = data['type'].value_counts().sort_index()\n",
    "    labels = ['House', 'Apartment']\n",
    "    plt.figure()\n",
    "    plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Property Type Distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === STEP 10: CORRELATION HEATMAP ===\n",
    "# Shows linear relationships between features. Useful for feature selection or multicollinearity checks.\n",
    "top_corr_cols = ['price', 'habitableSurface', 'bedroomCount', 'bathroomCount', 'buildingCondition', 'epcScore']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(data[top_corr_cols].corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap of Key Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === STEP 11: SCATTER PLOTS VS PRICE ===\n",
    "# Visual inspection of how some numeric features relate to price (check linearity, patterns)\n",
    "top_vars = ['habitableSurface', 'bedroomCount', 'bathroomCount']\n",
    "for var in top_vars:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.regplot(x=var, y='price', data=data, scatter_kws={'s': 10}, line_kws={'color': 'red'})\n",
    "    plt.title(f'Price vs {var}')\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel('Price')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === STEP 12: HISTOGRAM OF SURFACE AREAS ===\n",
    "# Shows how properties are distributed by size, filters out extreme outliers for better view.\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data[data['habitableSurface'] < 800]['habitableSurface'], bins=40, kde=True, color='green')\n",
    "plt.title('Distribution of Habitable Surface (<800 mÂ²)')\n",
    "plt.xlabel('Habitable Surface (mÂ²)')\n",
    "plt.ylabel('Number of Properties')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === STEP 13: PRICE PER MÂ² BY REGION AND TYPE ===\n",
    "# Tells us which regions/property types are most expensive per mÂ². Key for investment insights.\n",
    "if 'region_Flanders' in data.columns or 'region' in data.columns:\n",
    "    df_copy = data.copy()\n",
    "    if 'region' not in df_copy.columns:\n",
    "        def reverse_region(row):\n",
    "            if row.get('region_Flanders') == 1:\n",
    "                return 'Flanders'\n",
    "            elif row.get('region_Wallonia') == 1:\n",
    "                return 'Wallonia'\n",
    "            else:\n",
    "                return 'Brussels'\n",
    "        df_copy['region'] = df_copy.apply(reverse_region, axis=1)\n",
    "\n",
    "    df_filtered = df_copy[(df_copy['price'] > 100000) & (df_copy['price'] < 1000000)]\n",
    "    median_prices = df_filtered.groupby(['region', 'type'])['price_per_m2'].median().reset_index()\n",
    "\n",
    "    plot = sns.catplot(x=\"region\", y=\"price_per_m2\", hue=\"type\", kind=\"bar\", data=median_prices, palette=\"Set2\")\n",
    "    plt.title(\"Median Price per mÂ² by Region and Property Type\")\n",
    "    plot._legend.set_title(\"Property Type\")\n",
    "    plot._legend.texts[0].set_text(\"Apartment\")\n",
    "    plot._legend.texts[1].set_text(\"House\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
